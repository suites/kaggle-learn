{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Decision Tree Model\n",
    "\n",
    "Decision Tree를 이용한 가벼운 회귀 모델을 구현합니다.\n",
    "\n",
    "## 개요\n",
    "- **모델**: Decision Tree Regressor\n",
    "- **데이터**: Melbourne Housing Snapshot\n",
    "- **목표**: 주택 가격 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드\n",
    "melbourne_file_path = './input/melbourne-housing-snapshot/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path)\n",
    "\n",
    "# 결측치 제거\n",
    "melbourne_data = melbourne_data.dropna(axis=0)\n",
    "\n",
    "print(f\"데이터 크기: {melbourne_data.shape}\")\n",
    "print(f\"\\n데이터 컬럼:\")\n",
    "print(melbourne_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature 선택\n",
    "\n",
    "주택 가격 예측을 위한 주요 Feature들을 선택합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 대상 (target)\n",
    "y = melbourne_data.Price\n",
    "\n",
    "# Feature 선택 (수치형 변수들)\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                      'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "\n",
    "X = melbourne_data[melbourne_features]\n",
    "\n",
    "print(\"Features:\")\n",
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split\n",
    "\n",
    "데이터를 학습용과 검증용으로 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습/테스트 데이터 분리 (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"학습 데이터 크기: {X_train.shape}\")\n",
    "print(f\"테스트 데이터 크기: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decision Tree 모델 정의 및 학습\n",
    "\n",
    "### Decision Tree란?\n",
    "- 데이터를 분할하여 트리 구조로 예측하는 알고리즘\n",
    "- 해석이 용이하고 구현이 간단함\n",
    "- 과적합(Overfitting)에 주의 필요\n",
    "\n",
    "### 주요 하이퍼파라미터\n",
    "- `max_depth`: 트리의 최대 깊이 (과적합 방지)\n",
    "- `min_samples_split`: 노드를 분할하기 위한 최소 샘플 수\n",
    "- `min_samples_leaf`: 리프 노드의 최소 샘플 수\n",
    "- `random_state`: 재현성을 위한 시드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree 모델 생성 (가벼운 모델을 위해 max_depth 제한)\n",
    "model = DecisionTreeRegressor(\n",
    "    max_depth=5,           # 트리 깊이 제한 (가벼운 모델)\n",
    "    min_samples_split=20,  # 분할을 위한 최소 샘플 수\n",
    "    min_samples_leaf=10,   # 리프 노드 최소 샘플 수\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"모델 학습 완료!\")\n",
    "print(f\"트리 깊이: {model.get_depth()}\")\n",
    "print(f\"리프 노드 수: {model.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# 평가 지표 계산\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"모델 평가 결과\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\n[학습 데이터]\")\n",
    "print(f\"  MAE (Mean Absolute Error): ${train_mae:,.2f}\")\n",
    "print(f\"  RMSE (Root Mean Squared Error): ${train_rmse:,.2f}\")\n",
    "print(f\"  R² Score: {train_r2:.4f}\")\n",
    "\n",
    "print(f\"\\n[테스트 데이터]\")\n",
    "print(f\"  MAE (Mean Absolute Error): ${test_mae:,.2f}\")\n",
    "print(f\"  RMSE (Root Mean Squared Error): ${test_rmse:,.2f}\")\n",
    "print(f\"  R² Score: {test_r2:.4f}\")\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance\n",
    "\n",
    "어떤 Feature가 가격 예측에 가장 중요한지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 중요도\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': melbourne_features,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature 중요도:\")\n",
    "print(feature_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 예측 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음 5개 샘플에 대한 예측\n",
    "sample_predictions = pd.DataFrame({\n",
    "    'Actual Price': y_test.iloc[:5].values,\n",
    "    'Predicted Price': y_test_pred[:5],\n",
    "    'Difference': y_test.iloc[:5].values - y_test_pred[:5]\n",
    "})\n",
    "\n",
    "print(\"\\n실제 가격 vs 예측 가격 (처음 5개 샘플):\")\n",
    "print(sample_predictions.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 결론\n",
    "\n",
    "### Decision Tree 모델의 장점\n",
    "- 해석이 용이함 (Feature Importance 확인 가능)\n",
    "- 빠른 학습 및 예측 속도\n",
    "- 데이터 스케일링 불필요\n",
    "- 비선형 관계 포착 가능\n",
    "\n",
    "### Decision Tree 모델의 단점\n",
    "- 과적합 경향 (max_depth, min_samples_split 등으로 조절 필요)\n",
    "- 데이터 변화에 민감함\n",
    "- 예측 성능이 앙상블 모델에 비해 낮을 수 있음\n",
    "\n",
    "### 개선 방향\n",
    "- Random Forest, Gradient Boosting 등 앙상블 모델 사용\n",
    "- 하이퍼파라미터 튜닝 (GridSearchCV, RandomizedSearchCV)\n",
    "- 추가 Feature Engineering\n",
    "- Cross-Validation을 통한 모델 안정성 확보"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
